{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eae76a60",
   "metadata": {},
   "source": [
    "# Khai báo thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb9b6789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21a90872",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_yaml = r\"F:\\khodataset\\xe may oto\\data.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91535103",
   "metadata": {},
   "source": [
    "# Xuất các quantization model (fp16, int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eac94c",
   "metadata": {},
   "source": [
    "##  ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "018b9c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.191  Python-3.12.11 torch-2.8.0+cpu CPU (12th Gen Intel Core(TM) i5-12600H)\n",
      "WARNING half=True only compatible with GPU export, i.e. use device=0\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'onnx models\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 6, 8400) (18.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.2 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.65...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  3.9s, saved as 'onnx models\\best.onnx' (36.2 MB)\n",
      "\n",
      "Export complete (4.5s)\n",
      "Results saved to \u001b[1mG:\\smart-transportation-system\\app\\AI models\\model S\\onnx models\u001b[0m\n",
      "Predict:         yolo predict task=detect model=onnx models\\best.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=onnx models\\best.onnx imgsz=640 data=/kaggle/input/veheicle/duyet3/data.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Exported INT8 model: onnx models/best_int8.onnx\n"
     ]
    }
   ],
   "source": [
    "# 1. Load mô hình .pt\n",
    "model = YOLO(r\"onnx models/best.pt\")\n",
    "\n",
    "# 2. Xuất sang ONNX fp16\n",
    "\n",
    "model.export(\n",
    "    format=\"onnx\",  # Xuất ra ONNX\n",
    "    half = True,\n",
    "    dynamic=True, \n",
    "    simplify = True\n",
    ")\n",
    "\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "# File đầu vào  FP16\n",
    "model_fp16 = r\"onnx models/best.onnx\"\n",
    "model_int8 = r\"onnx models/best_int8.onnx\"\n",
    "\n",
    "# Quantization động (Dynamic Quantization)\n",
    "quantize_dynamic(\n",
    "    model_input=model_fp16, \n",
    "    model_output=model_int8,\n",
    "    weight_type=QuantType.QUInt8  # INT8\n",
    ")\n",
    "\n",
    "print(\"✅ Exported INT8 model:\", model_int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1897cd40",
   "metadata": {},
   "source": [
    "## OPENVINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1e010b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.191  Python-3.12.11 torch-2.8.0+cpu CPU (12th Gen Intel Core(TM) i5-12600H)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'openvino models\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 6, 8400) (18.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2025.2.0-19140-c01cd93e24d-releases/2025/2...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m collecting INT8 calibration images from 'data=F:\\khodataset\\xe may oto\\data.yaml'\n",
      "Fast image access  (ping: 0.00.0 ms, read: 163.2109.8 MB/s, size: 67.7 KB)\n",
      "\u001b[KScanning F:\\khodataset\\xe may oto\\valid\\labels.cache... 1115 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1115/1115 1112163.8it/s 0.0s\n",
      "WARNING:nncf:NNCF provides best results with torch==2.7.*, while current torch version is 2.8.0+cpu. If you encounter issues, consider switching to torch==2.7.*\n",
      "INFO:nncf:25 ignored nodes were found by patterns in the NNCFGraph\n",
      "INFO:nncf:1 ignored nodes were found by types in the NNCFGraph\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 181 __module.model.23.dfl/aten::view/Reshape\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 182 __module.model.23/aten::sigmoid/Sigmoid\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 198 __module.model.23.dfl/aten::transpose/Transpose\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 213 __module.model.23.dfl/aten::softmax/Softmax\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 226 __module.model.23.dfl.conv/aten::_convolution/Convolution\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 237 __module.model.23.dfl/aten::view/Reshape_1\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 260 __module.model.23/aten::sub/Subtract\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 261 __module.model.23/aten::add/Add_6\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 271 __module.model.23/aten::add/Add_7\n",
      "280 __module.model.23/aten::div/Divide\n",
      "\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 272 __module.model.23/aten::sub/Subtract_1\n",
      "INFO:nncf:Not adding activation input quantizer for operation: 246 __module.model.23/aten::mul/Multiply_3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success  94.7s, saved as 'openvino models\\best_int8_openvino_model\\' (9.8 MB)\n",
      "\n",
      "Export complete (95.2s)\n",
      "Results saved to \u001b[1mG:\\smart-transportation-system\\app\\AI models\\model S\\openvino models\u001b[0m\n",
      "Predict:         yolo predict task=detect model=openvino models\\best_int8_openvino_model imgsz=640 int8 \n",
      "Validate:        yolo val task=detect model=openvino models\\best_int8_openvino_model imgsz=640 data=/kaggle/input/veheicle/duyet3/data.yaml int8 \n",
      "Visualize:       https://netron.app\n",
      "Ultralytics 8.3.191  Python-3.12.11 torch-2.8.0+cpu CPU (12th Gen Intel Core(TM) i5-12600H)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'openvino models\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 6, 8400) (18.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2025.2.0-19140-c01cd93e24d-releases/2025/2...\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success  4.7s, saved as 'openvino models\\best_openvino_model\\' (18.4 MB)\n",
      "\n",
      "Export complete (5.4s)\n",
      "Results saved to \u001b[1mG:\\smart-transportation-system\\app\\AI models\\model S\\openvino models\u001b[0m\n",
      "Predict:         yolo predict task=detect model=openvino models\\best_openvino_model imgsz=640 half \n",
      "Validate:        yolo val task=detect model=openvino models\\best_openvino_model imgsz=640 data=/kaggle/input/veheicle/duyet3/data.yaml half \n",
      "Visualize:       https://netron.app\n",
      "✅ Xuất model OpenVINO thành công!\n"
     ]
    }
   ],
   "source": [
    "# 1. Load mô hình .pt\n",
    "model = YOLO(r\"openvino models/best.pt\")\n",
    "model.export(format=\"openvino\", dynamic=True, optimize=True, int8 = True, data = data_yaml)\n",
    "model.export(format=\"openvino\", dynamic=True, optimize=True, half = True, data = data_yaml)\n",
    "print(\"✅ Xuất model OpenVINO thành công!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c5d495",
   "metadata": {},
   "source": [
    "## MNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09e39bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.191  Python-3.12.11 torch-2.8.0+cpu CPU (12th Gen Intel Core(TM) i5-12600H)\n",
      "WARNING INT8 export requires a missing 'data' arg for calibration. Using default 'data=coco8.yaml'.\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'mnn models\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 6, 8400) (18.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.2 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.65...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.8s, saved as 'mnn models\\best.onnx' (36.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mMNN:\u001b[0m starting export with MNN 3.2.3...\n",
      "\u001b[34m\u001b[1mMNN:\u001b[0m export success  4.0s, saved as 'mnn models\\best.mnn' (9.3 MB)\n",
      "\n",
      "Export complete (4.7s)\n",
      "Results saved to \u001b[1mG:\\smart-transportation-system\\app\\AI models\\model S\\mnn models\u001b[0m\n",
      "Predict:         yolo predict task=detect model=mnn models\\best.mnn imgsz=640 int8 \n",
      "Validate:        yolo val task=detect model=mnn models\\best.mnn imgsz=640 data=/kaggle/input/veheicle/duyet3/data.yaml int8 \n",
      "Visualize:       https://netron.app\n",
      "Ultralytics 8.3.191  Python-3.12.11 torch-2.8.0+cpu CPU (12th Gen Intel Core(TM) i5-12600H)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'mnn models\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 6, 8400) (18.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.2 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.65...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.2s, saved as 'mnn models\\best.onnx' (36.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mMNN:\u001b[0m starting export with MNN 3.2.3...\n",
      "\u001b[34m\u001b[1mMNN:\u001b[0m export success  3.1s, saved as 'mnn models\\best.mnn' (18.1 MB)\n",
      "\n",
      "Export complete (3.9s)\n",
      "Results saved to \u001b[1mG:\\smart-transportation-system\\app\\AI models\\model S\\mnn models\u001b[0m\n",
      "Predict:         yolo predict task=detect model=mnn models\\best.mnn imgsz=640 half \n",
      "Validate:        yolo val task=detect model=mnn models\\best.mnn imgsz=640 data=/kaggle/input/veheicle/duyet3/data.yaml half \n",
      "Visualize:       https://netron.app\n",
      "✅ Xuất model MNN thành công!\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"mnn models/best.pt\")\n",
    "model.export(format=\"mnn\", int8=True)  # creates 'yolo11n.mnn' with int8 weight\n",
    "import os\n",
    "os.rename(\"mnn models/best.mnn\", \"mnn models/best_int8.mnn\")\n",
    "\n",
    "model.export(format=\"mnn\", half=True)  # creates 'yolo11n.mnn' with fp16 weight\n",
    "print(\"✅ Xuất model MNN thành công!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a66cd40",
   "metadata": {},
   "source": [
    "# VALIDATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87664d09",
   "metadata": {},
   "source": [
    "## MODEL GỐC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fd22a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.191  Python-3.12.11 torch-2.8.0+cpu CPU (12th Gen Intel Core(TM) i5-12600H)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 201.8173.3 MB/s, size: 61.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning F:\\khodataset\\xe may oto\\valid\\labels.cache... 1115 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1115/1115 1114018.3it/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 70/70 0.35it/s 3:182.8ss\n",
      "                   all       1115      10014      0.926       0.93      0.973      0.697\n",
      "                   car       1096       5940      0.935      0.959      0.982      0.763\n",
      "                 Motor        915       4074      0.916      0.902      0.964       0.63\n",
      "Speed: 1.0ms preprocess, 168.1ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(r\"original model\\best.pt\")\n",
    "results = model.val(data=data_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18246594",
   "metadata": {},
   "source": [
    "## ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2965bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
      "Ultralytics 8.3.191  Python-3.12.11 torch-2.8.0+cpu CPU (12th Gen Intel Core(TM) i5-12600H)\n",
      "Loading onnx models/best.onnx for ONNX Runtime inference...\n",
      "Using ONNX Runtime CPUExecutionProvider\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 402.1261.8 MB/s, size: 71.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning F:\\khodataset\\xe may oto\\valid\\labels.cache... 1115 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1115/1115 1113487.8it/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 70/70 0.36it/s 3:152.8ss\n",
      "                   all       1115      10014      0.926       0.93      0.973      0.697\n",
      "                   car       1096       5940      0.935      0.959      0.982      0.763\n",
      "                 Motor        915       4074      0.916      0.902      0.964       0.63\n",
      "Speed: 1.1ms preprocess, 161.8ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('onnx models/best.onnx')\n",
    "results = model.val(data=data_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f83275d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
      "Ultralytics 8.3.191  Python-3.12.11 torch-2.8.0+cpu CPU (12th Gen Intel Core(TM) i5-12600H)\n",
      "Loading onnx models/best_int8.onnx for ONNX Runtime inference...\n",
      "Using ONNX Runtime CPUExecutionProvider\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 574.1135.3 MB/s, size: 78.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning F:\\khodataset\\xe may oto\\valid\\labels.cache... 1115 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1115/1115 1113487.8it/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 70/70 0.18it/s 6:199.8ss\n",
      "                   all       1115      10014      0.923      0.926      0.969      0.682\n",
      "                   car       1096       5940      0.932      0.953       0.98      0.744\n",
      "                 Motor        915       4074      0.913      0.898      0.958      0.619\n",
      "Speed: 1.1ms preprocess, 326.8ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('onnx models/best_int8.onnx')\n",
    "results = model.val(data=data_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7b6480",
   "metadata": {},
   "source": [
    "## OPENVINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a5ae7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
      "Ultralytics 8.3.191  Python-3.12.11 torch-2.8.0+cpu CPU (12th Gen Intel Core(TM) i5-12600H)\n",
      "Loading openvino models/best_openvino_model for OpenVINO inference...\n",
      "Using OpenVINO LATENCY mode for batch=1 inference on (CPU)...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 258.3105.1 MB/s, size: 74.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning F:\\khodataset\\xe may oto\\valid\\labels.cache... 1115 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1115/1115 1117478.8it/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 70/70 0.67it/s 1:44.0ssss\n",
      "                   all       1115      10014      0.925       0.93      0.973      0.696\n",
      "                   car       1096       5940      0.935      0.959      0.982      0.762\n",
      "                 Motor        915       4074      0.915        0.9      0.964       0.63\n",
      "Speed: 0.9ms preprocess, 77.0ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('openvino models/best_openvino_model')\n",
    "results = model.val(data=data_yaml)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4600df58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
      "Ultralytics 8.3.191  Python-3.12.11 torch-2.8.0+cpu CPU (12th Gen Intel Core(TM) i5-12600H)\n",
      "Loading openvino models/best_int8_openvino_model for OpenVINO inference...\n",
      "Using OpenVINO LATENCY mode for batch=1 inference on (CPU)...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 264.396.5 MB/s, size: 78.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning F:\\khodataset\\xe may oto\\valid\\labels.cache... 1115 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1115/1115 557540.4it/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 70/70 0.65it/s 1:48.8s0ss\n",
      "                   all       1115      10014      0.925      0.927      0.972      0.692\n",
      "                   car       1096       5940      0.932      0.958      0.982      0.757\n",
      "                 Motor        915       4074      0.918      0.896      0.962      0.627\n",
      "Speed: 1.1ms preprocess, 86.1ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val7\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('openvino models/best_int8_openvino_model')\n",
    "results = model.val(data=data_yaml)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c3c023",
   "metadata": {},
   "source": [
    "# MNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a0c22ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
      "Ultralytics 8.3.191  Python-3.12.11 torch-2.8.0+cpu CPU (12th Gen Intel Core(TM) i5-12600H)\n",
      "Loading mnn models/best.mnn for MNN inference...\n",
      "Setting batch=1 input of shape (1, 3, 640, 640)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 275.1123.4 MB/s, size: 82.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning F:\\khodataset\\xe may oto\\valid\\labels.cache... 1115 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1115/1115 1066267.4it/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1115/1115 6.2it/s 2:59<0.2s\n",
      "                   all       1115      10014      0.923      0.929      0.969      0.694\n",
      "                   car       1096       5940      0.932      0.956      0.982      0.762\n",
      "                 Motor        915       4074      0.914      0.901      0.956      0.626\n",
      "Speed: 0.8ms preprocess, 147.1ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val8\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('mnn models/best.mnn')\n",
    "results = model.val(data=data_yaml)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5c6bc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
      "Ultralytics 8.3.191  Python-3.12.11 torch-2.8.0+cpu CPU (12th Gen Intel Core(TM) i5-12600H)\n",
      "Loading mnn models/best_int8.mnn for MNN inference...\n",
      "Setting batch=1 input of shape (1, 3, 640, 640)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 533.8224.5 MB/s, size: 85.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning F:\\khodataset\\xe may oto\\valid\\labels.cache... 1115 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1115/1115 1082307.1it/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1115/1115 6.3it/s 2:57<0.2s\n",
      "                   all       1115      10014      0.923       0.93      0.969      0.694\n",
      "                   car       1096       5940       0.93      0.956      0.982      0.762\n",
      "                 Motor        915       4074      0.917      0.903      0.956      0.625\n",
      "Speed: 0.9ms preprocess, 143.7ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val9\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('mnn models/best_int8.mnn')\n",
    "results = model.val(data=data_yaml)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
